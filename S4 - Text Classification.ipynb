{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2631db12",
   "metadata": {},
   "source": [
    "# Important !!!!\n",
    "\n",
    "        1.Pipeline takes list of tuples  Pipeline([   ('',fun()) , ('',fun())  ])\n",
    "        2.df.itertuples() works with 2 columns\n",
    "        3.for stopwords we need to create a list of stopwords using\n",
    "                from sklearn.preprocessing import text\n",
    "                stopwords = [text.ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce88f4",
   "metadata": {},
   "source": [
    "# 1 . Movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fc9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8947056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Natural language Processing/UPDATED_NLP_COURSE/TextFiles/moviereviews.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e165a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30f9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb12830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    983\n",
       "pos    982\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285ae584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 71,\n",
       " 147,\n",
       " 151,\n",
       " 283,\n",
       " 307,\n",
       " 313,\n",
       " 323,\n",
       " 343,\n",
       " 351,\n",
       " 427,\n",
       " 501,\n",
       " 633,\n",
       " 675,\n",
       " 815,\n",
       " 851,\n",
       " 977,\n",
       " 1079,\n",
       " 1299,\n",
       " 1455,\n",
       " 1493,\n",
       " 1525,\n",
       " 1531,\n",
       " 1763,\n",
       " 1851,\n",
       " 1905,\n",
       " 1993]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for blank values in message\n",
    "\n",
    "blank = []\n",
    "\n",
    "for index,label,review in df.itertuples():\n",
    "    if type(review)==str:\n",
    "        if review.isspace():\n",
    "            blank.append(index)\n",
    "\n",
    "blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfd5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blank,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbba7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d1f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    969\n",
       "neg    969\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ca3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0d07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7 , random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da54b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline takes list of tuples  Pipeline([   ('',fun()) , ('',fun())  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6435f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "txt_clf_lr = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                       ('lr',LogisticRegression())])\n",
    "\n",
    "txt_clf_svc = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                       ('svc',LinearSVC())])\n",
    "\n",
    "txt_clf_nb = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                       ('nb',MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e07642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_clf_lr.fit(X_train,y_train)\n",
    "txt_clf_svc.fit(X_train,y_train)\n",
    "txt_clf_nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2b9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = txt_clf_lr.predict(X_test)\n",
    "y_pred_svc = txt_clf_svc.predict(X_test)\n",
    "y_pred_nb = txt_clf_nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cabc1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.82      0.81       293\n",
      "         pos       0.81      0.81      0.81       289\n",
      "\n",
      "    accuracy                           0.81       582\n",
      "   macro avg       0.81      0.81      0.81       582\n",
      "weighted avg       0.81      0.81      0.81       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_pred_lr ,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a956ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.80      0.82       309\n",
      "         pos       0.79      0.83      0.81       273\n",
      "\n",
      "    accuracy                           0.81       582\n",
      "   macro avg       0.81      0.82      0.81       582\n",
      "weighted avg       0.82      0.81      0.81       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_nb ,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7233cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.85      0.85       297\n",
      "         pos       0.84      0.85      0.84       285\n",
      "\n",
      "    accuracy                           0.85       582\n",
      "   macro avg       0.85      0.85      0.85       582\n",
      "weighted avg       0.85      0.85      0.85       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_svc ,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d1ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_clf_svc.predict(['Great movie for boredom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643fe87",
   "metadata": {},
   "source": [
    "#  SMS SPAM ? HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70cdd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stopwords = [text.ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e29673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Natural language Processing/UPDATED_NLP_COURSE/TextFiles/smsspamcollection.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5799d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping because df.itertuples() works only when 2 columns ie label & message\n",
    "df.drop(['length','punct'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2300f0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ecf49f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c89de692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7736dcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for blank spaces in message\n",
    "blanks = []\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)\n",
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b499f002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59e4bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6bef1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7 , random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6f89ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "txt_clf_tree =  Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),\n",
    "                          ('tree',DecisionTreeClassifier())])\n",
    "\n",
    "txt_clf_gb = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),\n",
    "                        ('gbc',GradientBoostingClassifier()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f23b4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=[frozenset({'a', 'about', 'above',\n",
       "                                                        'across', 'after',\n",
       "                                                        'afterwards', 'again',\n",
       "                                                        'against', 'all',\n",
       "                                                        'almost', 'alone',\n",
       "                                                        'along', 'already',\n",
       "                                                        'also', 'although',\n",
       "                                                        'always', 'am', 'among',\n",
       "                                                        'amongst', 'amoungst',\n",
       "                                                        'amount', 'an', 'and',\n",
       "                                                        'another', 'any',\n",
       "                                                        'anyhow', 'anyone',\n",
       "                                                        'anything', 'anyway',\n",
       "                                                        'anywhere', ...})])),\n",
       "                ('tree', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_clf_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a34fd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tree = txt_clf_tree.predict(X_test)\n",
    "y_pred_tree[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6191f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.98      0.98      1475\n",
      "        spam       0.88      0.82      0.85       197\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.93      0.90      0.91      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fd4b750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=[frozenset({'a', 'about', 'above',\n",
       "                                                        'across', 'after',\n",
       "                                                        'afterwards', 'again',\n",
       "                                                        'against', 'all',\n",
       "                                                        'almost', 'alone',\n",
       "                                                        'along', 'already',\n",
       "                                                        'also', 'although',\n",
       "                                                        'always', 'am', 'among',\n",
       "                                                        'amongst', 'amoungst',\n",
       "                                                        'amount', 'an', 'and',\n",
       "                                                        'another', 'any',\n",
       "                                                        'anyhow', 'anyone',\n",
       "                                                        'anything', 'anyway',\n",
       "                                                        'anywhere', ...})])),\n",
       "                ('gbc', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_clf_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d6b6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gb = txt_clf_gb.predict(X_test)\n",
    "y_pred_gb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e71f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1475\n",
      "        spam       0.97      0.79      0.87       197\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.97      0.89      0.93      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b38ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
